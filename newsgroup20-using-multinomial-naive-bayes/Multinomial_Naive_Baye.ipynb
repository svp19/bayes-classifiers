{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multinomial Naive Bayes Classifier - Newsgroup 20 Dataset",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "crCApqjNRtN0"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from tqdm import tqdm\r\n",
        "from collections import Counter\r\n",
        "\r\n",
        "from sklearn.datasets import fetch_20newsgroups\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\r\n",
        "from sklearn.preprocessing import LabelBinarizer\r\n",
        "from sklearn import metrics"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVw2sgDVSXQ2"
      },
      "source": [
        "class MultinomialNaiveBayes():\r\n",
        "\r\n",
        "  def __init__(self, alpha=0.01):\r\n",
        "    self.alpha = alpha\r\n",
        "  \r\n",
        "\r\n",
        "  def predict(self, X):\r\n",
        "    # (N', W) . (num_classes, num_words)\r\n",
        "    log_likelihood = np.dot(X, self.word_conditional_log_probs.T) + self.log_class_priors\r\n",
        "    return np.argmax(log_likelihood, axis=1)\r\n",
        "\r\n",
        "\r\n",
        "  def get_class_priors(self, y_encoded):\r\n",
        "    # how many documents belong to each class (num_classes, )\r\n",
        "    self.class_counts = np.sum(y_encoded, axis=0)\r\n",
        "\r\n",
        "    # log class priors\r\n",
        "    self.log_class_priors =  np.log(self.class_counts) - np.log(self.class_counts.sum())\r\n",
        "\r\n",
        "  \r\n",
        "  def get_word_conditional_log_probs(self, X, y_encoded):\r\n",
        "    # for each class, how many times did a particular word occur (num_classes, num_words)\r\n",
        "    word_counts_per_class = np.dot(y_encoded.T, X)\r\n",
        "\r\n",
        "    # smoothen word_counts_per_class (num_classes, num_words)\r\n",
        "    wcpc_laplace = word_counts_per_class + self.alpha\r\n",
        "    \r\n",
        "    #for each class, how many words occured totally in all documents (num_classes, 1)\r\n",
        "    total_wcpc = wcpc_laplace.sum(axis=1).reshape(-1, 1)\r\n",
        "\r\n",
        "    # P(w/C) (num_classes, num_words)\r\n",
        "    self.word_conditional_log_probs = np.log(wcpc_laplace) - np.log(total_wcpc)\r\n",
        "  \r\n",
        "\r\n",
        "  def fit(self, X, y):\r\n",
        "    '''\r\n",
        "    N: number of classes\r\n",
        "    W: number of words in vocabulary\r\n",
        "    '''\r\n",
        "    self.N, self.W = X.shape\r\n",
        "    label_binarizer = LabelBinarizer()\r\n",
        "    y_encoded = label_binarizer.fit_transform(y)\r\n",
        "    self.get_class_priors(y_encoded)\r\n",
        "    self.get_word_conditional_log_probs(X, y_encoded)\r\n",
        "    return self"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTN7YZ_kE6m2"
      },
      "source": [
        "## Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQuWnb_VUFd1",
        "outputId": "a3dd36cc-12d4-42fd-9dce-6c3584f02aa9"
      },
      "source": [
        "newsgroups_train = fetch_20newsgroups(subset='train')\r\n",
        "newsgroups_test = fetch_20newsgroups(subset='test')\r\n",
        "vectorizer = CountVectorizer(max_features=50000) #TfidfVectorizer()\r\n",
        "vectors = vectorizer.fit_transform(newsgroups_train.data)\r\n",
        "vectors_test = vectorizer.transform(newsgroups_test.data)\r\n",
        "\r\n",
        "clf = MultinomialNaiveBayes(alpha=.005)\r\n",
        "clf.fit(vectors.toarray(), newsgroups_train.target)\r\n",
        "pred = clf.predict(vectors_test.toarray())\r\n",
        "print('F1 Score : ', metrics.f1_score(newsgroups_test.target, pred, average='macro'))\r\n",
        "print('Accuracy : ', (pred == newsgroups_test.target).mean())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 Score :  0.7819812580122694\n",
            "Accuracy :  0.7993892724375996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHX0tzq2VSov",
        "outputId": "2a379fd8-70a8-4eff-b7a2-0639878ab0e6"
      },
      "source": [
        "pred = clf.predict(vectors.toarray())\r\n",
        "print('F1 Score : ', metrics.f1_score(newsgroups_train.target, pred, average='macro'))\r\n",
        "print('Accuracy : ', (pred == newsgroups_train.target).mean())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 Score :  0.9660375041002223\n",
            "Accuracy :  0.9681810146720877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD1y6qloWEv3"
      },
      "source": [
        "## TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Oeabr1LCs_E",
        "outputId": "2a0b97bf-f7b6-45df-8ca2-fea24dc93dbc"
      },
      "source": [
        "newsgroups_train = fetch_20newsgroups(subset='train')\r\n",
        "newsgroups_test = fetch_20newsgroups(subset='test')\r\n",
        "vectorizer = TfidfVectorizer() #TfidfVectorizer()\r\n",
        "vectors = vectorizer.fit_transform(newsgroups_train.data)\r\n",
        "vectors_test = vectorizer.transform(newsgroups_test.data)\r\n",
        "\r\n",
        "clf = MultinomialNaiveBayes(alpha=.005)\r\n",
        "clf.fit(vectors.toarray(), newsgroups_train.target)\r\n",
        "pred = clf.predict(vectors_test.toarray())\r\n",
        "print('F1 Score : ', metrics.f1_score(newsgroups_test.target, pred, average='macro'))\r\n",
        "print('Accuracy : ', (pred == newsgroups_test.target).mean())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 Score :  0.8270729497003412\n",
            "Accuracy :  0.8325809877854488\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqzryLBRCuqY",
        "outputId": "268ef279-667e-45c7-fc66-d3466ab3e3f6"
      },
      "source": [
        "pred = clf.predict(vectors.toarray())\r\n",
        "print('F1 Score : ', metrics.f1_score(newsgroups_train.target, pred, average='macro'))\r\n",
        "print('Accuracy : ', (pred == newsgroups_train.target).mean())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 Score :  0.9978309568664306\n",
            "Accuracy :  0.9977903482411172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqPRVBn2DM4B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}